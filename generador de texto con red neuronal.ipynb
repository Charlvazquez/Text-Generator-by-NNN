{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#introduccion a generacion de texto con red neuronal\n",
    "#las redes neuronales recurrentes son muy utilidas cuando se va a la procesion dee datos secuenciales como texto.\n",
    "#En esta practica vamos a usar una red neuronal LSTM(Long short term memory o termino de memoria de corta a larga)\n",
    "#para enseñar a nuestra computadora a escribir textos como shakespeare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Primero vamos a cargar las liberarias que vamos a emplear.\n",
    "#En este caso Tensorflow, Numpy y Random.\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.layers import Activation, Dense, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Primero que nada necesitamos una cantidad larga de enunciados de texto de shakespeare para entrenar el modelo.\n",
    "#por lo que vamos podemos yasea descargar uno o hacer uso de uno de una pagina.\n",
    "filepath = tf.keras.utils.get_file('shakespeare.txt',\n",
    "        'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
    "text = open(filepath, 'rb').read().decode(encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ahora bien lo siguiente es convertir el formato del texto en algo que la red neuronal pueda entender.\n",
    "#Por lo que necesitamos convertir todos esos valores a datos numericos.\n",
    "text = open(filepath, 'rb').read().decode(encoding='utf-8').lower()\n",
    "#en caso de que no se quiera usar todo el texto o una parte limitada, se puede emplear un .lower(),\n",
    "#para reducir todo lo que se vaya a convertir, esto con el fin de no demorar en convertir todo el fragmento de texto.\n",
    "#A parte de producir un mejor resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aqui vamos a seleccionar a todos los caracteres de numero de 300,000 caracteres hasta 800,000.\n",
    "#Estamos produciendo un total de 500,000 caracteres, los cuales deberian ser suficientes para resultados muy decentes.\n",
    "text = text[300000:800000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ahora vamos a crear un tipo de conjunto de todos los caracteres unicos que ocurren en el texto.\n",
    "#En un no conjunto aparecen mas de una vez,lo cual es una forma de filtrar los caracteres.\n",
    "characters = sorted(set(text))\n",
    "#Despues de eso, definimos dos estructuras para convertir los valores.\n",
    "#Ambas son diccionarios que enumeran los caracteres.\n",
    "char_to_index = dict((c, i) for i, c in enumerate(characters))\n",
    "#En el primero, los caracteres son las llaves y los indices son los valores.\n",
    "index_to_char = dict((i, c) for i, c in enumerate(characters))\n",
    "#En el segundo es viceversa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#En el siguiente paso, vamos a definir que tan largo debe ser la secuencia y tambien cuantos caracteres\n",
    "#seguira para empezar el siguiente enunciado.\n",
    "#Lo que trataremos de hacer aqui es tomar los enunciados y entonces guardarlos en la siguiente letra como un dato de entrenamiento.\n",
    "SEQ_LENGTH = 40\n",
    "STEP_SIZE = 3\n",
    "\n",
    "sentences = []\n",
    "next_charl = []\n",
    "\n",
    "#iteramos a traves de todo el texto y reunir todos los enunciados y sus siguientes caracteres.\n",
    "#Este es el dato de entrenamiento para nuestra red reuronal.\n",
    "#Ahora necesitamos convertirlo en un formato numerico.\n",
    "for i in range(0, len(text) - SEQ_LENGTH, STEP_SIZE):\n",
    "    sentences.append(text[i: i + SEQ_LENGTH])\n",
    "    next_charl.append(text[i + SEQ_LENGTH])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se crearan dos arreglos de Numpy todos de zeros.\n",
    "#El tipo de datos es booleano. Donde un caracter aparezca en varios enunciados en una posicion certera.\n",
    "#lo coloraremos a uno o a un True. Tendremos una dimension para los enunciados.\n",
    "#Una dimension para la posicion de los caracteres dentro de los enunciados y una dimension para especificar\n",
    "#Que caracter esta en esa posicion.\n",
    "\n",
    "x = np.zeros((len(sentences), SEQ_LENGTH,\n",
    "              len(characters)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences),\n",
    "              len(characters)), dtype=np.bool)\n",
    "\n",
    "for i, satz in enumerate(sentences):\n",
    "    for t, char in enumerate(satz):\n",
    "        x[i, t, char_to_index[char]] = 1\n",
    "    y[i, char_to_index[next_charl[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\anaconda\\envs\\Cuz\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "#Creacion de modelo\n",
    "#Usaremos Sequential para nuestro modelo,activacion, densidad y LSTM para nuestros layers\n",
    "#y RMSprop para la optimizacion durante la compilacion de nuestro modelo.\n",
    "#LSTM soporta para long-short-term-memory y este tipo de estracto recurrente n las redes neuronales.\n",
    "#podria ser llamado la memoria de nuestro modelo.Este es crucial,desde que estamos tratando con datos secuenciales.\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(SEQ_LENGTH, len(characters))))\n",
    "model.add(Dense(len(characters)))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\anaconda\\envs\\Cuz\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 166654 samples\n",
      "Epoch 1/4\n",
      "166654/166654 [==============================] - 72s 430us/sample - loss: 2.1257\n",
      "Epoch 2/4\n",
      "166654/166654 [==============================] - 79s 474us/sample - loss: 1.7156\n",
      "Epoch 3/4\n",
      "166654/166654 [==============================] - 80s 479us/sample - loss: 1.5887\n",
      "Epoch 4/4\n",
      "166654/166654 [==============================] - 85s 513us/sample - loss: 1.5227\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x257cf4abe48>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x,y, batch_size=256, epochs=4)\n",
    "#Ahora compilaremos el modelo y entrenarlo con nuestros datos de entrenamiento que preparamos por encima.\n",
    "#Escogemos el tamaño de lote de 256(el cual puedes cambiar si quieres) y 4 epoca. Esto significa que nuestro modelo vera el mismo tipo de dato 4 veces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#se guarda el modelo creado \n",
    "model.save('textgenerator.model') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\anaconda\\envs\\Cuz\\lib\\site-packages\\tensorflow_core\\python\\ops\\init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\anaconda\\envs\\Cuz\\lib\\site-packages\\tensorflow_core\\python\\ops\\init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\anaconda\\envs\\Cuz\\lib\\site-packages\\tensorflow_core\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "#se carga el modelo\n",
    "model = tf.keras.models.load_model('textgenerator.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nuestro modelo esta ahora entrenado pero solo las salidas de las posibilidades para el siguiente caracter.\n",
    "#Entonces necesitamos alguna funcion adicional para hacer que nuestro guion genere un texto razonable.\n",
    "#Esta funcion de ayuda llamada nuestra puedes usarla de la pagina de keras.\n",
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "#Es basicamente elegir uno de los caracteres de la salida. como parametros tomara el resultado de la prediccion y una temperatura.\n",
    "#Esta temperatura indica que tan riesgoso el elegir debe ser.\n",
    "#Si tenemos una temperatura alta, elegiremos uno de los caracteres menos probables.\n",
    "#Una temperatura baja causara una eleccion conservativa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(length, temperature):\n",
    "    start_index = random.randint(0, len(text) - SEQ_LENGTH - 1)\n",
    "    generated = ''\n",
    "    sentence = text[start_index: start_index + SEQ_LENGTH]\n",
    "    generated += sentence\n",
    "    for i in range(length):\n",
    "        x_predictions = np.zeros((1, SEQ_LENGTH, len(characters)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x_predictions[0, t, char_to_index[char]] = 1\n",
    "\n",
    "        predictions = model.predict(x_predictions, verbose=0)[0]\n",
    "        next_index = sample(predictions,\n",
    "                                 temperature)\n",
    "        next_character = index_to_char[next_index]\n",
    "\n",
    "        generated += next_character\n",
    "        sentence = sentence[1:] + next_character\n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------0.2---------\n",
      "d the hand of war,\n",
      "this happy breed of my lord, the banish\n",
      "and man and my love, that she would not for her soul.\n",
      "\n",
      "king richard ii:\n",
      "then the did my soul in the words him stand\n",
      "and then the words him not the words the words,\n",
      "and thou wilt the words of the words of his comes\n",
      "and be with the words a bust to the words,\n",
      "when the words the words\n",
      "--------0.4---------\n",
      "to let you understand,\n",
      "if case some one to the words have strees,\n",
      "and then where we well to his makes for him now,\n",
      "stay the distand richard his sir, as which we warwick\n",
      "as soul my words me with a roush the warwick,\n",
      "and therefore and will do the cate the words,\n",
      "where is not the day with my matter of his fair\n",
      "the will my lord, there is a be\n",
      "--------0.6---------\n",
      "royalties and to beg\n",
      "enfranchisement immor livest the sun the eneminis\n",
      "make for her will strong with surper'd of wence,\n",
      "but what is become your fortunes good,\n",
      "and for the sweat the receity, for this been,\n",
      "as we are with meet when thou ween he that i will to the straight.\n",
      "\n",
      "romeo:\n",
      "i that that sid words and night and in and heart,\n",
      "when they \n",
      "--------0.8---------\n",
      "scouts have found the adventure very east.\n",
      "\n",
      "juliet:\n",
      "i'll hear all shill with the were for those.\n",
      "\n",
      "romeo:\n",
      "i am tongues my fast.\n",
      "\n",
      "camillo:\n",
      "you have thou may! where not is not is but read.\n",
      "\n",
      "sir dream:\n",
      "we prower he warget in our hovering compond\n",
      "and make beh of likes of son.\n",
      "\n",
      "pring brater,\n",
      "there is no light of his place is of chargace\n",
      "us with\n",
      "--------1---------\n",
      "glory,\n",
      "and rob his temples of the diadem's de tamples\n",
      "to did all agains and woft edward.\n",
      "\n",
      "duke of york:\n",
      "i was now ever'd wrong here well in'th's swift.\n",
      "\n",
      "york:\n",
      "wills lady that there from us upon: his liege.\n",
      "is there's my downar i am creak of that come and two\n",
      "\n",
      "stful ars eageralies will a fill.\n",
      "\n",
      "dost edumiss:\n",
      "bearing more strong are rossel \n"
     ]
    }
   ],
   "source": [
    "print('--------0.2---------')\n",
    "print(generate_text(300,0.2))\n",
    "print('--------0.4---------')\n",
    "print(generate_text(300,0.4))\n",
    "print('--------0.6---------')\n",
    "print(generate_text(300,0.6))\n",
    "print('--------0.8---------')\n",
    "print(generate_text(300,0.8))\n",
    "print('--------1---------')\n",
    "print(generate_text(300,1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
